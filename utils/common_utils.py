#!/usr/bin/env python3
"""
TensorFlowå­¦ä¹ é¡¹ç›®é€šç”¨å·¥å…·å‡½æ•°
åŒ…å«æ•°æ®å¤„ç†ã€å¯è§†åŒ–ã€æ¨¡å‹è¯„ä¼°ç­‰å¸¸ç”¨åŠŸèƒ½
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Tuple, List, Optional

def print_section(title: str, width: int = 60):
    """æ‰“å°å¸¦æ ¼å¼çš„ç« èŠ‚æ ‡é¢˜"""
    print("=" * width)
    print(f"ğŸ”§ {title}")
    print("=" * width)

def print_tensor_info(tensor: tf.Tensor, name: str = "Tensor"):
    """æ‰“å°å¼ é‡çš„è¯¦ç»†ä¿¡æ¯"""
    print(f"{name}ä¿¡æ¯:")
    print(f"  å½¢çŠ¶: {tensor.shape}")
    print(f"  æ•°æ®ç±»å‹: {tensor.dtype}")
    print(f"  å¤§å°: {tf.size(tensor).numpy()}")
    print(f"  å€¼:\n{tensor}")

def generate_sample_data(n_samples: int = 100, 
                        n_features: int = 1, 
                        noise: float = 0.1,
                        seed: int = 42) -> Tuple[tf.Tensor, tf.Tensor]:
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®ç”¨äºå­¦ä¹ """
    tf.random.set_seed(seed)
    np.random.seed(seed)
    
    # ç”Ÿæˆç‰¹å¾
    X = tf.random.uniform([n_samples, n_features], -2.0, 2.0)
    
    # ç”Ÿæˆæ ‡ç­¾ (çº¿æ€§å…³ç³» + å™ªå£°)
    true_w = tf.constant([1.5] * n_features, dtype=tf.float32)
    true_b = tf.constant(0.5, dtype=tf.float32)
    
    y = tf.matmul(X, tf.expand_dims(true_w, 1)) + true_b
    y = y + tf.random.normal([n_samples, 1], stddev=noise)
    
    return X, tf.squeeze(y)

def plot_data_2d(X: tf.Tensor, y: tf.Tensor, 
                title: str = "æ•°æ®å¯è§†åŒ–",
                xlabel: str = "X", 
                ylabel: str = "y"):
    """ç»˜åˆ¶2Dæ•°æ®ç‚¹"""
    plt.figure(figsize=(8, 6))
    plt.scatter(X.numpy(), y.numpy(), alpha=0.6)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.grid(True, alpha=0.3)
    plt.show()

def plot_loss_history(loss_history: List[float], 
                     title: str = "è®­ç»ƒæŸå¤±å†å²"):
    """ç»˜åˆ¶æŸå¤±å‡½æ•°å˜åŒ–å†å²"""
    plt.figure(figsize=(10, 6))
    plt.plot(loss_history)
    plt.xlabel("è®­ç»ƒè½®æ¬¡")
    plt.ylabel("æŸå¤±å€¼")
    plt.title(title)
    plt.grid(True, alpha=0.3)
    plt.show()

def normalize_data(data: tf.Tensor, 
                  method: str = "zscore") -> Tuple[tf.Tensor, dict]:
    """æ•°æ®æ ‡å‡†åŒ–"""
    if method == "zscore":
        mean = tf.reduce_mean(data, axis=0)
        std = tf.math.reduce_std(data, axis=0)
        normalized = (data - mean) / (std + 1e-8)
        stats = {"mean": mean, "std": std}
    
    elif method == "minmax":
        min_val = tf.reduce_min(data, axis=0)
        max_val = tf.reduce_max(data, axis=0)
        normalized = (data - min_val) / (max_val - min_val + 1e-8)
        stats = {"min": min_val, "max": max_val}
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ‡å‡†åŒ–æ–¹æ³•: {method}")
    
    return normalized, stats

def split_data(X: tf.Tensor, y: tf.Tensor, 
              train_ratio: float = 0.8,
              seed: int = 42) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
    """åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
    tf.random.set_seed(seed)
    
    n_samples = X.shape[0]
    n_train = int(n_samples * train_ratio)
    
    # éšæœºæ‰“ä¹±ç´¢å¼•
    indices = tf.random.shuffle(tf.range(n_samples))
    train_indices = indices[:n_train]
    test_indices = indices[n_train:]
    
    X_train = tf.gather(X, train_indices)
    y_train = tf.gather(y, train_indices)
    X_test = tf.gather(X, test_indices)
    y_test = tf.gather(y, test_indices)
    
    return X_train, X_test, y_train, y_test

def calculate_metrics(y_true: tf.Tensor, y_pred: tf.Tensor) -> dict:
    """è®¡ç®—å›å½’æŒ‡æ ‡"""
    # å‡æ–¹è¯¯å·®
    mse = tf.reduce_mean(tf.square(y_true - y_pred))
    
    # å¹³å‡ç»å¯¹è¯¯å·®
    mae = tf.reduce_mean(tf.abs(y_true - y_pred))
    
    # RÂ²å†³å®šç³»æ•°
    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))
    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))
    r2 = 1 - ss_res / ss_tot
    
    return {
        "MSE": mse.numpy(),
        "MAE": mae.numpy(),
        "RÂ²": r2.numpy()
    }

def print_metrics(metrics: dict, title: str = "æ¨¡å‹è¯„ä¼°æŒ‡æ ‡"):
    """æ‰“å°è¯„ä¼°æŒ‡æ ‡"""
    print(f"\nğŸ“Š {title}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")

def create_batches(X: tf.Tensor, y: tf.Tensor, 
                  batch_size: int = 32) -> tf.data.Dataset:
    """åˆ›å»ºæ‰¹æ¬¡æ•°æ®"""
    dataset = tf.data.Dataset.from_tensor_slices((X, y))
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

def plot_predictions(X: tf.Tensor, y_true: tf.Tensor, y_pred: tf.Tensor,
                    title: str = "é¢„æµ‹ç»“æœå¯¹æ¯”"):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœå¯¹æ¯”"""
    if X.shape[1] == 1:  # ä¸€ç»´ç‰¹å¾
        plt.figure(figsize=(10, 6))
        
        # æ’åºä»¥ä¾¿ç»˜åˆ¶å¹³æ»‘çš„çº¿
        sorted_indices = tf.argsort(tf.squeeze(X))
        X_sorted = tf.gather(X, sorted_indices)
        y_true_sorted = tf.gather(y_true, sorted_indices)
        y_pred_sorted = tf.gather(y_pred, sorted_indices)
        
        plt.scatter(X.numpy(), y_true.numpy(), alpha=0.6, label="çœŸå®å€¼")
        plt.plot(X_sorted.numpy(), y_pred_sorted.numpy(), 'r-', label="é¢„æµ‹å€¼")
        
        plt.xlabel("X")
        plt.ylabel("y")
        plt.title(title)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()
    else:
        # å¤šç»´ç‰¹å¾æ—¶ç»˜åˆ¶çœŸå®å€¼vsé¢„æµ‹å€¼æ•£ç‚¹å›¾
        plt.figure(figsize=(8, 8))
        plt.scatter(y_true.numpy(), y_pred.numpy(), alpha=0.6)
        
        # ç»˜åˆ¶y=xå‚è€ƒçº¿
        min_val = min(tf.reduce_min(y_true), tf.reduce_min(y_pred))
        max_val = max(tf.reduce_max(y_true), tf.reduce_max(y_pred))
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', label="ç†æƒ³é¢„æµ‹")
        
        plt.xlabel("çœŸå®å€¼")
        plt.ylabel("é¢„æµ‹å€¼")
        plt.title(title)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

def save_model_summary(model, filepath: str = "model_summary.txt"):
    """ä¿å­˜æ¨¡å‹æ‘˜è¦åˆ°æ–‡ä»¶"""
    with open(filepath, 'w', encoding='utf-8') as f:
        model.summary(print_fn=lambda x: f.write(x + '\n'))
    print(f"æ¨¡å‹æ‘˜è¦å·²ä¿å­˜åˆ°: {filepath}")

def check_tensorflow_setup():
    """æ£€æŸ¥TensorFlowç¯å¢ƒè®¾ç½®"""
    print("ğŸ” TensorFlowç¯å¢ƒæ£€æŸ¥:")
    print(f"  TensorFlowç‰ˆæœ¬: {tf.__version__}")
    print(f"  æ˜¯å¦å¯ç”¨æ€¥åˆ‡æ‰§è¡Œ: {tf.executing_eagerly()}")
    
    # æ£€æŸ¥GPU
    gpu_devices = tf.config.list_physical_devices('GPU')
    if gpu_devices:
        print(f"  æ£€æµ‹åˆ°GPU: {len(gpu_devices)}ä¸ª")
        for i, gpu in enumerate(gpu_devices):
            print(f"    GPU {i}: {gpu}")
    else:
        print("  GPU: æœªæ£€æµ‹åˆ°")
    
    # æ£€æŸ¥å†…å­˜
    print(f"  é€»è¾‘CPUæ•°é‡: {len(tf.config.list_logical_devices('CPU'))}")
    
    return True

# ç¤ºä¾‹ä½¿ç”¨
if __name__ == "__main__":
    print_section("TensorFlowå·¥å…·å‡½æ•°æµ‹è¯•")
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_tensorflow_setup()
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    print("\nğŸ“Š ç”Ÿæˆç¤ºä¾‹æ•°æ®:")
    X, y = generate_sample_data(n_samples=50, noise=0.2)
    print_tensor_info(X, "ç‰¹å¾X")
    print_tensor_info(y, "æ ‡ç­¾y")
    
    # æ•°æ®æ ‡å‡†åŒ–
    print("\nğŸ“ æ•°æ®æ ‡å‡†åŒ–:")
    X_norm, stats = normalize_data(X)
    print(f"æ ‡å‡†åŒ–ç»Ÿè®¡: {stats}")
    
    # æ•°æ®åˆ’åˆ†
    print("\nğŸ“‚ æ•°æ®åˆ’åˆ†:")
    X_train, X_test, y_train, y_test = split_data(X, y)
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}")
    
    print("\nâœ… å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ!") 